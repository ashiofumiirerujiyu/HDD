{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nms import nms\n",
    "from progress.bar import Bar\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pgm_image(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        header = f.readline().decode('ascii')\n",
    "        assert header.strip() == 'P5', \"PGM 파일이 아니거나 지원되지 않는 PGM 형식입니다.\"\n",
    "        \n",
    "        # 주석 건너뛰기\n",
    "        while True:\n",
    "            line = f.readline().decode('ascii')\n",
    "            if line[0] != '#':\n",
    "                break\n",
    "        \n",
    "        # 너비와 높이 읽기\n",
    "        width, height = [int(i) for i in line.split()]\n",
    "        max_val = int(f.readline().decode('ascii'))  # 최대 픽셀 값 (예: 255)\n",
    "        \n",
    "        # 이미지 데이터 읽기\n",
    "        img = np.fromfile(f, dtype=np.uint8).reshape((height, width))\n",
    "        \n",
    "        return img\n",
    "\n",
    "def load_all_pgms(folder_path):\n",
    "    pgm_images = []\n",
    "    \n",
    "    # 폴더 내 모든 PGM 파일 불러오기\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.pgm'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            img = load_pgm_image(file_path)\n",
    "            pgm_images.append(img)\n",
    "    \n",
    "    # 이미지 리스트를 NumPy 배열로 변환\n",
    "    pgm_images_array = np.array(pgm_images)\n",
    "    \n",
    "    return pgm_images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X: (6977, 19, 19)\n",
      "train y: (6977,)\n"
     ]
    }
   ],
   "source": [
    "train_face_folder_path = '/workspace/mlcnn/mitcbcl/train/face'\n",
    "train_non_face_folder_path = '/workspace/mlcnn/mitcbcl/train/non-face'\n",
    "\n",
    "train_face_images = load_all_pgms(train_face_folder_path)\n",
    "train_non_face_images = load_all_pgms(train_non_face_folder_path)\n",
    "\n",
    "train_X = np.concatenate([train_face_images, train_non_face_images], axis=0)\n",
    "train_y = np.zeros(len(train_face_images) + len(train_non_face_images))\n",
    "train_y[:len(train_face_images)] = 1\n",
    "\n",
    "print(f\"train X: {train_X.shape}\")\n",
    "print(f\"train y: {train_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test X: (24045, 19, 19)\n",
      "test y: (24045,)\n"
     ]
    }
   ],
   "source": [
    "test_face_folder_path = '/workspace/mlcnn/mitcbcl/test/face'\n",
    "test_non_face_folder_path = '/workspace/mlcnn/mitcbcl/test/non-face'\n",
    "\n",
    "test_face_images = load_all_pgms(test_face_folder_path)\n",
    "test_non_face_images = load_all_pgms(test_non_face_folder_path)\n",
    "\n",
    "test_X = np.concatenate([test_face_images, test_non_face_images], axis=0)\n",
    "test_y = np.zeros(len(test_face_images) + len(test_non_face_images))\n",
    "test_y[:len(test_face_images)] = 1\n",
    "\n",
    "print(f\"test X: {test_X.shape}\")\n",
    "print(f\"test y: {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Make Haar filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectangleRegion:\n",
    "    def __init__(self, x, y, width, height):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "    def compute_region(self, ii, scale=1.0):\n",
    "        x1 = int(self.x * scale)\n",
    "        y1 = int(self.y * scale)\n",
    "        x2 = x1 + int(self.width * scale) - 1\n",
    "        y2 = y1 + int(self.height * scale) - 1\n",
    "\n",
    "        # 사각형 영역 내 적분 이미지 값 계산\n",
    "        S = int(ii[x2, y2])\n",
    "        if x1 > 0: S -= int(ii[x1-1, y2])\n",
    "        if y1 > 0: S -= int(ii[x2, y1-1])\n",
    "        if x1 > 0 and y1 > 0: S += int(ii[x1 - 1, y1 - 1])\n",
    "        return S  # 부호 없는 값으로 인한 계산 보정\n",
    "\n",
    "class HaarFeature:\n",
    "    def __init__(self, positive_regions, negative_regions):\n",
    "        self.positive_regions = positive_regions  # 흰색 영역\n",
    "        self.negative_regions = negative_regions  # 검은색 영역\n",
    "\n",
    "    def compute_value(self, ii, scale=1.0):\n",
    "        \"\"\"\n",
    "        적분 이미지에서 특징 값 계산\n",
    "        \"\"\"\n",
    "        sum_pos = sum([rect.compute_region(ii, scale) for rect in self.positive_regions])\n",
    "        sum_neg = sum([rect.compute_region(ii, scale) for rect in self.negative_regions])\n",
    "        return sum_neg - sum_pos  # 특징 값은 검은색 영역에서 흰색 영역을 뺀 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_filters(img_w, img_h, shift=1, scale_factor=1.25, min_w=4, min_h=4):\n",
    "    \"\"\"\n",
    "    Haar 특징으로 필터 생성\n",
    "\n",
    "    흰색 사각형에서 검은색 사각형 값을 뺌\n",
    "    \"\"\"\n",
    "    filters = []  # [Tuple(positive regions, negative regions),...]\n",
    "\n",
    "    # 특징 창 크기 조정\n",
    "    for w_width in range(min_w, img_w + 1):\n",
    "        for w_height in range(min_h, img_h + 1):\n",
    "\n",
    "            # 이미지 전체 순회\n",
    "            x = 0\n",
    "            while x + w_width < img_w:\n",
    "                y = 0\n",
    "                while y + w_height < img_h:\n",
    "\n",
    "                    # 가능한 Haar 영역 설정\n",
    "                    immediate = RectangleRegion(x, y, w_width, w_height)  # |X|\n",
    "                    right = RectangleRegion(x + w_width, y, w_width, w_height)  # | |X|\n",
    "                    right_2 = RectangleRegion(x + w_width * 2, y, w_width, w_height)  # | | |X|\n",
    "                    bottom = RectangleRegion(x, y + w_height, w_width, w_height)  # | |/|X|\n",
    "                    bottom_right = RectangleRegion(x + w_width, y + w_height, w_width, w_height)  # | |/| |X|\n",
    "\n",
    "                    # [Haar] 2개의 사각형 *********\n",
    "                    # 수평 (흰색-검은색)\n",
    "                    if x + w_width * 2 < img_w:\n",
    "                        filters.append(HaarFeature([immediate], [right]))\n",
    "                    # 수직 (흰색-검은색)\n",
    "                    if y + w_height * 2 < img_h:\n",
    "                        filters.append(HaarFeature([bottom], [immediate]))\n",
    "\n",
    "                    # [Haar] 3개의 사각형 *********\n",
    "                    # 수평 (흰색-검은색-흰색)\n",
    "                    if x + w_width * 3 < img_w:\n",
    "                        filters.append(HaarFeature([immediate, right_2], [right]))\n",
    "\n",
    "                    # [Haar] 4개의 사각형 *********\n",
    "                    if x + w_width * 2 < img_w and y + w_height * 2 < img_h:\n",
    "                        filters.append(HaarFeature([immediate, bottom_right], [bottom, right]))\n",
    "\n",
    "                    y += shift\n",
    "                x += shift\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters(X_ii, filters):\n",
    "    \"\"\"\n",
    "    학습 데이터(적분 이미지)에 필터 적용\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.zeros((len(filters), len(X_ii)), dtype=np.int32)\n",
    "\n",
    "    bar = Bar('필터 처리 중', max=len(filters), suffix='%(percent)d%% - %(elapsed_td)s - %(eta_td)s')\n",
    "    for j, feature in bar.iter(enumerate(filters)):\n",
    "        # 필터 'j'의 값을 학습 이미지들에 대해 계산 (각 분류기의 입력으로 사용)\n",
    "        X[j] = list(map(lambda ii: feature.compute_value(ii), X_ii))\n",
    "    bar.finish()\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integral_image(img):\n",
    "    \"\"\"\n",
    "    합산 영역 테이블의 최적화 버전\n",
    "    ii(-1, y) = 0  # 좌측 경계 처리\n",
    "    s(x, -1) = 0  # 상단 경계 처리\n",
    "    s(x, y) = s(x, y-1) + i(x, y)  # 열 X의 y 레벨까지의 합\n",
    "    ii(x, y) = ii(x-1, y) + s(x, y)  # (X-1, Y) 위치의 적분 이미지 + 열 X의 y 레벨까지의 합\n",
    "    \"\"\"\n",
    "    h, w = img.shape\n",
    "\n",
    "    s = np.zeros(img.shape, dtype=np.uint32)  # 각 열의 누적 합을 저장할 배열\n",
    "    ii = np.zeros(img.shape, dtype=np.uint32)  # 적분 이미지 배열\n",
    "\n",
    "    for x in range(0, w):\n",
    "        for y in range(0, h):\n",
    "            # 현재 픽셀을 포함한 y까지의 열 합 계산\n",
    "            s[y][x] = s[y - 1][x] + img[y][x] if y - 1 >= 0 else img[y][x]\n",
    "            # 적분 이미지 계산 (이전 열의 적분값과 현재 열의 누적 합을 더함)\n",
    "            ii[y][x] = ii[y][x - 1] + s[y][x] if x - 1 >= 0 else s[y][x]\n",
    "    \n",
    "    return ii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakClassifier:\n",
    "\n",
    "    def __init__(self, haar_feature=None, threshold=None, polarity=None):\n",
    "        # 약한 분류기 초기화\n",
    "        self.haar_feature = haar_feature\n",
    "        self.threshold = threshold\n",
    "        self.polarity = polarity\n",
    "\n",
    "    def classify(self, ii, scale=1.0):\n",
    "        \"\"\"\n",
    "        적분 이미지 'ii'와 스케일이 주어졌을 때 분류를 수행\n",
    "        \"\"\"\n",
    "        # 주어진 적분 이미지에서 Haar feature 값 계산\n",
    "        feature_value = self.haar_feature.compute_value(ii, scale)\n",
    "        # polarity와 임계값을 사용하여 분류\n",
    "        return 1 if self.polarity * feature_value < self.polarity * self.threshold * (scale**2) else 0\n",
    "\n",
    "    def classify_f(self, feature_value):\n",
    "        \"\"\"\n",
    "        주어진 feature 값 또는 배열을 사용하여 분류\n",
    "        \"\"\"\n",
    "        # polarity와 feature 값 비교 후 분류\n",
    "        a = self.polarity * feature_value\n",
    "        b = self.polarity * self.threshold\n",
    "        return np.less(a, b).astype(int)\n",
    "\n",
    "    def train(self, X, y, weights, total_pos_weights=None, total_neg_weights=None):\n",
    "        # 긍정/부정 가중치 합 계산 (주어지지 않은 경우)\n",
    "        if not total_pos_weights:\n",
    "            total_pos_weights = np.sum(weights[np.where(y == 1)])\n",
    "        if not total_neg_weights:\n",
    "            total_neg_weights = np.sum(weights[np.where(y == 0)])\n",
    "\n",
    "        # feature 값 기준으로 정렬\n",
    "        sorted_features = sorted(zip(weights, X, y), key=lambda a: a[1])\n",
    "\n",
    "        pos_seen, neg_seen = 0, 0\n",
    "        sum_pos_weights, sum_neg_weights = 0, 0\n",
    "        min_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
    "\n",
    "        for w, f, label in sorted_features:\n",
    "            # 오차 계산: 긍정/부정 가중치 중 작은 값 선택\n",
    "            error = min(\n",
    "                sum_neg_weights + (total_pos_weights - sum_pos_weights),\n",
    "                sum_pos_weights + (total_neg_weights - sum_neg_weights)\n",
    "            )\n",
    "\n",
    "            # 최소 오차인 경우 임계값과 polarity 업데이트\n",
    "            if error < min_error:\n",
    "                min_error = error\n",
    "                self.threshold = f\n",
    "                self.polarity = 1 if pos_seen > neg_seen else -1\n",
    "\n",
    "            # 레이블에 따라 가중치와 카운트 업데이트\n",
    "            if label == 1:\n",
    "                pos_seen += 1\n",
    "                sum_pos_weights += w\n",
    "            else:\n",
    "                neg_seen += 1\n",
    "                sum_neg_weights += w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    \"\"\"\n",
    "    분류 오류가 높은 샘플에 대해 더 높은 가중치를 부여함으로써 해당 샘플이 더 중요하게 다뤄지도록 만듭니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_estimators=10):\n",
    "        # AdaBoost 초기화: n_estimators는 약한 분류기의 수\n",
    "        self.n_estimators = n_estimators\n",
    "        self.alphas = []  # 약한 분류기 가중치\n",
    "        self.clfs = []  # 약한 분류기 리스트\n",
    "\n",
    "    def train(self, X, y, features, X_ii):\n",
    "        # 긍정, 부정 샘플 수 계산\n",
    "        pos_num = np.sum(y)\n",
    "        neg_num = len(y) - pos_num\n",
    "        weights = np.zeros(len(y), dtype=np.float32)\n",
    "\n",
    "        # 초기 가중치 설정\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == 1:  # 긍정 샘플\n",
    "                weights[i] = 1.0 / (pos_num * 2.0)\n",
    "            else:  # 부정 샘플\n",
    "                weights[i] = 1.0 / (neg_num * 2.0)\n",
    "\n",
    "        print(\"Training...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 각 약한 분류기를 학습\n",
    "        for t in range(self.n_estimators):\n",
    "            print(f\"Training {t + 1} classifiers out of {self.n_estimators}\")\n",
    "\n",
    "            # 가중치 정규화\n",
    "            w_sum = np.sum(weights)\n",
    "            if w_sum == 0.0:\n",
    "                print(\"[WARNING] EARLY STOP. WEIGHTS ARE ZERO.\")\n",
    "                break\n",
    "            weights = weights / w_sum\n",
    "\n",
    "            # 약한 분류기 학습\n",
    "            print(\"Training weak classifiers...\")\n",
    "            weak_classifiers = self.train_estimators(X, y, weights, features)\n",
    "\n",
    "            # 가장 낮은 오차를 가진 약한 분류기 선택\n",
    "            print(\"Selecting best weak classifiers...\")\n",
    "            clf, error, incorrectness = self.select_best(weak_classifiers, X, y, weights)\n",
    "\n",
    "            if error <= 0.5:\n",
    "                # alpha와 beta 계산\n",
    "                beta = error / (1.0 - error)\n",
    "                alpha = math.log(1.0 / (beta + 1e-18))\n",
    "\n",
    "                # 가중치 업데이트\n",
    "                weights = np.multiply(weights, beta ** (1 - incorrectness))\n",
    "\n",
    "                # 최종 분류기 및 가중치 저장\n",
    "                self.alphas.append(alpha)\n",
    "                self.clfs.append(clf)\n",
    "            else:\n",
    "                print(error)\n",
    "                print(\"WHAT THE FUCK!????\")\n",
    "\n",
    "        print(f\"<== Training completed. Num. classifiers: {self.n_estimators}\")\n",
    "\n",
    "    def train_estimators(self, X, y, weights, features):\n",
    "        # 약한 분류기 학습\n",
    "        weak_clfs = []\n",
    "        total_pos_weights, total_neg_weights = 0, 0\n",
    "\n",
    "        for w, label in zip(weights, y):\n",
    "            if label == 1:\n",
    "                total_pos_weights += w\n",
    "            else:\n",
    "                total_neg_weights += w\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            # 각 feature에 대해 약한 분류기 학습\n",
    "            clf = WeakClassifier(haar_feature=features[i])\n",
    "            clf.train(X[i], y, weights, total_pos_weights, total_neg_weights)\n",
    "            weak_clfs.append(clf)\n",
    "\n",
    "        return weak_clfs\n",
    "\n",
    "    def select_best(self, weak_clfs, X, y, weights):\n",
    "        # 최적의 약한 분류기를 선택\n",
    "        best_clf, min_error, best_accuracy = None, float('inf'), None\n",
    "\n",
    "        for i, clf in enumerate(weak_clfs):\n",
    "            # 오차 계산\n",
    "            incorrectness = np.abs(clf.classify_f(X[i]) - y)\n",
    "            error = float(np.sum(np.multiply(incorrectness, weights))) / len(incorrectness)\n",
    "\n",
    "            # 최소 오차를 가진 분류기 선택\n",
    "            if error < min_error:\n",
    "                best_clf, min_error, best_accuracy = clf, error, incorrectness\n",
    "\n",
    "        return best_clf, min_error, best_accuracy\n",
    "\n",
    "    def classify(self, X, scale=1.0):\n",
    "        # 최종 분류 수행: 여러 약한 분류기의 가중치를 반영한 결과 반환\n",
    "        total = sum(list(map(lambda x: x[0] * x[1].classify(X, scale), zip(self.alphas, self.clfs))))\n",
    "        return 1 if total >= 0.5 * sum(self.alphas) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViolaJones:\n",
    "\n",
    "    def __init__(self, layers, features_path=None):\n",
    "        assert isinstance(layers, list)\n",
    "        self.layers = layers  # 약한 분류기의 개수(T)를 포함한 리스트\n",
    "        self.clfs = []\n",
    "        self.base_width, self.base_height = 19, 19  # 학습 데이터셋 이미지의 기본 크기\n",
    "        self.base_scale, self.shift = 1.25, 2\n",
    "        self.features_path = features_path  # 특징 저장 경로\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        N개의 Viola-Jones 분류기(AdaBoost)를 점점 복잡하게 학습시킴.\n",
    "        첫 번째 분류기 이후에는, 각 분류기는 양성 예시와 이전 분류기의 \n",
    "        오탐(false positive) 예시에 대해 학습함.\n",
    "        \"\"\"\n",
    "        print(\"데이터 준비 중...\")\n",
    "\n",
    "        # 학습 데이터 준비\n",
    "        pos_num = np.sum(y)  # 양성 예시 개수\n",
    "        neg_num = len(y) - pos_num  # 음성 예시 개수\n",
    "        img_h, img_w = X[0].shape  # 모든 학습 이미지는 동일한 크기를 가짐\n",
    "\n",
    "        # 양성 및 음성 샘플 분리\n",
    "        pos_indices = np.where(y == 1)[0]\n",
    "        neg_indices = np.where(y == 0)[0]\n",
    "\n",
    "        # 데이터 정보 출력\n",
    "        print(\"입력 데이터 요약:\")\n",
    "        print(\"\\t- 얼굴 개수: {:,} ({:.2f}%)\".format(int(pos_num), 100.0 * pos_num / (pos_num + neg_num)))\n",
    "        print(\"\\t- 얼굴이 아닌 이미지 개수: {:,} ({:.2f}%)\".format(int(neg_num), 100.0 * neg_num / (pos_num + neg_num)))\n",
    "        print(\"\\t- 전체 샘플 수: {:,}\".format(int(pos_num + neg_num)))\n",
    "        print(\"\\t- 이미지 크기 (가로x세로): {}x{}\".format(img_w, img_h))\n",
    "\n",
    "        # 가중치 초기화 및 적분 이미지 생성\n",
    "        print(\"적분 이미지 생성 중...\")\n",
    "        start_time = time.time()\n",
    "        X_ii = np.array(list(map(lambda x: integral_image(x), X)), dtype=np.uint32)\n",
    "        print(\"\\t- 적분 이미지 개수: {:,}\".format(len(X_ii)))\n",
    "\n",
    "        # 필터 생성 및 적용\n",
    "        print(\"필터 생성 중...\")\n",
    "        start_time = time.time()\n",
    "        features = build_filters(img_w, img_h)  # 모든 이미지에 동일한 필터 사용\n",
    "        print(\"\\t- 생성된 필터 수: {:,}\".format(len(features)))\n",
    "\n",
    "        print(\"필터 적용 중...\")\n",
    "        start_time = time.time()\n",
    "        X_f = self.__load_feature_dataset()  # 저장된 특징 데이터셋 불러오기 (존재하는 경우)\n",
    "        if X_f is None:\n",
    "            X_f = apply_filters(X_ii, features)\n",
    "\n",
    "            if self.features_path:  # 특징 저장\n",
    "                np.save(self.features_path + \"xf\" + \".npy\", X_f)\n",
    "                print(\"적용된 특징 파일 저장 완료!\")\n",
    "        print(\"\\t- 적용된 특징 수: {:,}\".format(len(X_f) * len(features)))\n",
    "\n",
    "        # Cascade 방식의 Viola-Jones 분류기 학습 (AdaBoost)\n",
    "        for i, t in enumerate(self.layers):\n",
    "            print(\"[CascadeClassifier] {}층 중 {}번째 층 학습 중\".format(len(self.layers), i+1))\n",
    "            if len(neg_indices) == 0:\n",
    "                print('조기 종료: 모든 샘플이 올바르게 분류되었습니다.')\n",
    "                break\n",
    "\n",
    "            # 샘플 인덱스를 섞음\n",
    "            tr_idxs = np.concatenate([pos_indices, neg_indices])\n",
    "            np.random.shuffle(tr_idxs)\n",
    "\n",
    "            # Viola-Jones (AdaBoost) 학습\n",
    "            clf = AdaBoost(n_estimators=t)\n",
    "            clf.train(X_f[:, tr_idxs], y[tr_idxs], features, X_ii[tr_idxs])\n",
    "            self.clfs.append(clf)\n",
    "\n",
    "            # 얼굴이 아닌 이미지 중 얼굴로 분류된 false positive 탐지\n",
    "            false_positives = []\n",
    "            for neg_idx in neg_indices:\n",
    "                if self.classify(X[neg_idx]) == 1:\n",
    "                    false_positives.append(neg_idx)\n",
    "            neg_indices = np.array(false_positives)\n",
    "\n",
    "    def classify(self, image, scale=1.0):\n",
    "        \"\"\"\n",
    "        얼굴이 아닌 것으로 판정되면 즉시 종료.\n",
    "        얼굴이 아닐 경우 계속해서 검사 진행.\n",
    "        \"\"\"\n",
    "        return self.classify_ii(integral_image(image), scale)\n",
    "\n",
    "    def classify_ii(self, ii, scale=1.0):\n",
    "        \"\"\"\n",
    "        얼굴이 아닌 것으로 판정되면 즉시 종료.\n",
    "        얼굴이 아닐 경우 계속해서 검사 진행.\n",
    "        \"\"\"\n",
    "        for clf in self.clfs:  # ViolaJones 분류기\n",
    "            if clf.classify(ii, scale) == 0:\n",
    "                return 0\n",
    "        return 1\n",
    "\n",
    "    def find_faces(self, pil_image):\n",
    "        \"\"\"\n",
    "        PIL 이미지에서 얼굴을 탐지\n",
    "        \"\"\"\n",
    "        w, h, s = (self.base_width, self.base_height, self.base_scale)\n",
    "        regions = []\n",
    "\n",
    "        # 이미지 전처리 (흑백 변환)\n",
    "        pil_image = pil_image.convert('L')\n",
    "        image = np.array(pil_image)\n",
    "        img_h, img_w = image.shape\n",
    "\n",
    "        # 적분 이미지 계산\n",
    "        ii = integral_image(image)\n",
    "\n",
    "        # 슬라이딩 윈도우 탐색\n",
    "        # 탐색 영역의 크기가 이미지보다 작아야 함\n",
    "        counter = 0\n",
    "        while int(w * s) < img_w and int(h * s) < img_h:\n",
    "\n",
    "            # 탐색 영역이 이미지 범위 안에 있어야 함\n",
    "            for y1 in np.arange(0, int(img_h) - int(h * s), self.shift):\n",
    "                for x1 in np.arange(0, int(img_w) - int(w * s), self.shift):\n",
    "                    y1, x1 = int(y1), int(x1)\n",
    "                    y2, x2 = y1 + int(h * s), x1 + int(w * s)\n",
    "                    cropped_img = ii[y1:y2, x1:x2]\n",
    "\n",
    "                    if self.classify_ii(cropped_img, scale=s):  # CascadeClassifier를 통한 분류\n",
    "                        regions.append((x1, y1, x2, y2))\n",
    "\n",
    "                    counter += 1\n",
    "                    print(\"분석된 크롭 수: {}\".format(counter))\n",
    "\n",
    "            # 탐색 윈도우 크기 확대\n",
    "            w *= s\n",
    "            h *= s\n",
    "\n",
    "        return regions\n",
    "\n",
    "    def save(self, filename):\n",
    "        with open(filename + \".pkl\", 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def __load_feature_dataset(self):\n",
    "        X_f = None\n",
    "        # 사전 계산된 특징 데이터셋 로드\n",
    "        try:\n",
    "            if self.features_path:\n",
    "                X_f = np.load(self.features_path + \"xf\" + \".npy\")\n",
    "                print(\"사전 계산된 데이터셋 로드 완료!\")\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        return X_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Viola-Jones 훈련 중...\n",
      "데이터 준비 중...\n",
      "입력 데이터 요약:\n",
      "\t- 얼굴 개수: 2,429 (34.81%)\n",
      "\t- 얼굴이 아닌 이미지 개수: 4,548 (65.19%)\n",
      "\t- 전체 샘플 수: 6,977\n",
      "\t- 이미지 크기 (가로x세로): 19x19\n",
      "적분 이미지 생성 중...\n",
      "\t- 적분 이미지 개수: 6,977\n",
      "필터 생성 중...\n",
      "\t- 생성된 필터 수: 11,376\n",
      "필터 적용 중...\n",
      "적용된 특징 파일 저장 완료!\n",
      "\t- 적용된 특징 수: 129,413,376\n",
      "[CascadeClassifier] 4층 중 1번째 층 학습 중\n",
      "Training...\n",
      "Training 1 classifiers out of 1\n",
      "Training weak classifiers...\n",
      "Selecting best weak classifiers...\n",
      "<== Training completed. Num. classifiers: 1\n",
      "[CascadeClassifier] 4층 중 2번째 층 학습 중\n",
      "Training...\n",
      "Training 1 classifiers out of 1\n",
      "Training weak classifiers...\n",
      "Selecting best weak classifiers...\n",
      "<== Training completed. Num. classifiers: 1\n",
      "[CascadeClassifier] 4층 중 3번째 층 학습 중\n",
      "Training...\n",
      "Training 1 classifiers out of 1\n",
      "Training weak classifiers...\n",
      "Selecting best weak classifiers...\n",
      "<== Training completed. Num. classifiers: 1\n",
      "[CascadeClassifier] 4층 중 4번째 층 학습 중\n",
      "Training...\n",
      "Training 1 classifiers out of 1\n",
      "Training weak classifiers...\n",
      "Selecting best weak classifiers...\n",
      "<== Training completed. Num. classifiers: 1\n",
      "훈련 완료!\n",
      "\n",
      "가중치 저장 중...\n",
      "가중치 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nViola-Jones 훈련 중...\")\n",
    "features_path = '/workspace/HDD/save/'\n",
    "clf = ViolaJones(layers=[1, 1, 1, 1], features_path=features_path)\n",
    "clf.train(train_X, train_y)  # X_f (선택 사항, 훈련 속도 향상용)\n",
    "print(\"훈련 완료!\")\n",
    "\n",
    "# 가중치 저장\n",
    "print(\"\\n가중치 저장 중...\")\n",
    "clf.save(features_path + 'cvj_weights_' + str(int(time.time())))\n",
    "print(\"가중치 저장 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf, X, y, show_samples=False):\n",
    "    metrics = {}\n",
    "    true_positive, true_negative = 0, 0  # 올바른 예측 수\n",
    "    false_positive, false_negative = 0, 0  # 잘못된 예측 수\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        prediction = clf.classify(X[i])\n",
    "        if prediction == y[i]:  # 올바른 예측\n",
    "            if prediction == 1:  # 얼굴\n",
    "                true_positive += 1\n",
    "            else:  # 비얼굴\n",
    "                true_negative += 1\n",
    "        else:  # 잘못된 예측\n",
    "            # if show_samples: show_sample(X[i], y[i], prediction)\n",
    "\n",
    "            if prediction == 1:  # 얼굴\n",
    "                false_positive += 1\n",
    "            else:  # 비얼굴\n",
    "                false_negative += 1\n",
    "\n",
    "    # 지표 계산\n",
    "    metrics['true_positive'] = true_positive\n",
    "    metrics['true_negative'] = true_negative\n",
    "    metrics['false_positive'] = false_positive\n",
    "    metrics['false_negative'] = false_negative\n",
    "\n",
    "    metrics['accuracy'] = (true_positive + true_negative) / (true_positive + false_negative + true_negative + false_positive)  # 정확도\n",
    "    metrics['precision'] = true_positive / (true_positive + false_positive)  # 정밀도\n",
    "    metrics['recall'] = true_positive / (true_positive + false_negative)  # 재현율 또는 민감도\n",
    "    metrics['specifity'] = true_negative / (true_negative + false_positive)  # 특이도\n",
    "    metrics['f1'] = (2.0 * metrics['precision'] * metrics['recall']) / (metrics['precision'] + metrics['recall'])  # F1 점수\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "평가 중...\n",
      "지표: [test]\n",
      "\t- true_positive: 4\n",
      "\t- true_negative: 23,454\n",
      "\t- false_positive: 119\n",
      "\t- false_negative: 468\n",
      "\t- accuracy: 0.976\n",
      "\t- precision: 0.033\n",
      "\t- recall: 0.008\n",
      "\t- specifity: 0.995\n",
      "\t- f1: 0.013\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "name = \"test\"\n",
    "print(\"\\n평가 중...\")\n",
    "metrics = evaluate(clf, test_X, test_y, show_samples=False)\n",
    "\n",
    "print(\"지표: [{}]\".format(name))\n",
    "counter = 0\n",
    "for k, v in metrics.items():\n",
    "    counter += 1\n",
    "    if counter <= 4:\n",
    "        print(\"\\t- {}: {:,}\".format(k, v))\n",
    "    else:\n",
    "        print(\"\\t- {}: {:.3f}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(pil_image, regions, color=\"green\", thickness=3):\n",
    "    # 이미지를 준비합니다.\n",
    "    source_img = pil_image.convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(source_img)\n",
    "    for rect in regions:\n",
    "        draw.rectangle(tuple(rect), outline=color, width=thickness)\n",
    "    return source_img\n",
    "\n",
    "\n",
    "def find_faces(weight_path, face_path):\n",
    "    # 분류기 가중치를 로드합니다.\n",
    "    clf = ViolaJones.load(weight_path)\n",
    "\n",
    "    # 얼굴의 영역을 찾습니다.\n",
    "    numpy_img = load_pgm_image(face_path)\n",
    "    pil_img = Image.fromarray(numpy_img)\n",
    "    regions = clf.find_faces(pil_img)\n",
    "\n",
    "    # 바운딩 박스를 그립니다.\n",
    "    # TODO: 비최대 억제(Non-maximum suppression) 검토 (자체 구현 수정)\n",
    "    scores = [1.0] * len(regions)  #np.ones(len(regions))\n",
    "    indicies = nms.boxes(regions, scores)\n",
    "    regions = np.array(regions)\n",
    "    print(f\"scores: {scores}\")\n",
    "    print(f\"regions: {regions}\")\n",
    "\n",
    "    drawn_img = draw_bounding_boxes(pil_img, list(regions[indicies]), thickness=1)\n",
    "    # drawn_img = draw_bounding_boxes(pil_img, list(regions), thickness=1)\n",
    "\n",
    "    # 이미지를 표시합니다.\n",
    "    plt.imshow(drawn_img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: []\n",
      "regions: []\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_path = \"/workspace/HDD/savecvj_weights_1729217241.pkl\"\n",
    "face_path = \"/workspace/mlcnn/mitcbcl/test/face/cmu_0000.pgm\"\n",
    "\n",
    "find_faces(weight_path, face_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
